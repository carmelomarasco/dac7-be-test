spring.application.name=Boundary-Service
server.port=9080
spring.banner.location=banner.txt
###### METRICS ##################
management.endpoints.web.exposure.include=health,info,metrics,prometheus
management.endpoint.metrics.enabled=true
management.endpoint.prometheus.enabled=true
management.metrics.export.prometheus.enabled=true
###### METRICS ##################
#######APPLICATION MONITORING################
#Actuator Configuration (default is /actuator)
info.app.name=Boundary Service Application
info.app.description=Servizio di frontiera che trasforma le chiamare rest esterne in eventi fruibili dal sistema di microservizi.
info.app.version=1.0.0
#port used to expose actuator
#management.server.port=9081
#management.endpoint.metrics.enabled=true
#management.endpoints.web.exposure.include=metrics
#######APPLICATION MONITORING################
#######KAFKA PRODUCER SETTING################
# ID to pass to the server when making requests. Used for server-side logging.
spring.kafka.client-id=Boundary-Service
# Nummber of retry to contact Kafka
spring.kafka.producer.retries=5
# Comma-delimited list of host:port pairs to use for establishing the initial connections to the Kafka cluster. Overrides the global property, for producers.
spring.kafka.producer.bootstrap-servers=${SERVERS_KAFKA}
# Serializer for key and value
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
# Set producer name
producer.producer-name=BOUNDARY_SERVICE
spring.sleuth.messaging.kafka.enabled=false
spring.kafka.producer.properties.max.request.size=5242880
spring.kafka.producer.acks=all
spring.kafka.properties.enable.idempotence=true
spring.kafka.properties.transactional.id=${MY_ADDRESS}
#######KAFKA PRODUCER SETTING################
#######KAFKA CONSUMER SETTING################
# Unique string that identifies the consumer group to which this consumer belongs.
spring.kafka.consumer.group-id=Boundary-service
# Comma-delimited list of host:port pairs to use for establishing the initial connections to the Kafka cluster. Overrides the global property, for consumers.
spring.kafka.consumer.bootstrap-servers=${SERVERS_KAFKA}
# What to do when there is no initial offset in Kafka or if the current offset no longer exists on the server.
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.listener.ack-mode=manual
spring.kafka.consumer.isolation-level=read_committed
#######KAFKA CONSUMER SETTING################
#######TOPIC SETTING################
topic.boundaryServiceCommand=${TOPIC_BOUNDARY_SERVICE_COMMAND}
topic.boundaryServiceError=${TOPIC_BOUNDARY_SERVICE_ERROR}
topic.boundaryServiceDac6Command=${TOPIC_BOUNDARY_SERVICE_DAC6_COMMAND}
topic.boundaryServiceDac6Event=${TOPIC_BOUNDARY_SERVICE_DAC6_EVENT}
topic.boundaryServiceDac6Error=${TOPIC_BOUNDARY_SERVICE_DAC6_ERROR}
topic.boundaryServiceCrsCommand=${TOPIC_BOUNDARY_SERVICE_CRS_COMMAND}
topic.boundaryServiceCrsEvent=${TOPIC_BOUNDARY_SERVICE_CRS_EVENT}
topic.boundaryServiceCrsError=${TOPIC_BOUNDARY_SERVICE_CRS_ERROR}
topic.boundaryServiceDpiCommand=${TOPIC_BOUNDARY_SERVICE_DPI_COMMAND}
topic.boundaryServiceDpiEvent=${TOPIC_BOUNDARY_SERVICE_DPI_EVENT}
topic.boundaryServiceDpiError=${TOPIC_BOUNDARY_SERVICE_DPI_ERROR}
#######TOPIC SETTING################
#######EVENT SETTING################
event.name.accepted=${EVENT_ACCEPTED_COMMUNICATION}
event.name.rejected=${EVENT_REJECTED_COMMUNICATION}
event.name.acceptedNonContributing=${EVENT_ACCEPTED_NON_CONTRIBUTING}
event.name.eventError=${EVENT_ERROR}
event.name.eventErrorDac6=${EVENT_ERROR_DAC6}
event.name.replaced=${EVENT_REPLACED_COMMUNICATION}
event.name.canceled=${EVENT_CANCELED_COMMUNICATION}
event.name.newIncomingRequest=${EVENT_NEW_INCOMING_REQUEST}
#######EVENT SETTING################
########KAFKA SECURITY################
#spring.kafka.properties.security.protocol=SASL_SSL
#spring.kafka.properties.sasl.mechanism=SCRAM-SHA-256
#spring.kafka.properties.ssl.truststore.location=/config/resources/security/truststore.jks
#spring.kafka.properties.ssl.truststore.password=${PSW_TRUSTSTORE}
#spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USER-ENT-SA-0178_FU_041}" password="${KAFKA_PASSWORD-ENT-SA-0178_FU_041}";
########KAFKA SECURITY################
#######DATABASE##################
spring.datasource.hikari.connection-timeout=20000
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.maximum-pool-size=12
spring.datasource.hikari.idle-timeout=300000
spring.datasource.hikari.max-lifetime=1200000
#spring.datasource.jndi-name=jdbc/boundaryService
spring.datasource.url=jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=TCP)(HOST=10.50.5.48)(PORT=1630))(ADDRESS=(PROTOCOL=TCP)(HOST=26.2.63.54)(PORT=1630))(ADDRESS=(PROTOCOL=TCP)(HOST=26.0.137.67)(PORT=1521)))(SOURCE_ROUTE=yes)(CONNECT_DATA=(SERVICE_NAME=DB12U6)))
spring.datasource.username=${DB_USERNAME}
spring.datasource.password=${DB_PASSWORD}
spring.datasource.driver-class=oracle.jdbc.OracleDriver
#######DATABASE##################