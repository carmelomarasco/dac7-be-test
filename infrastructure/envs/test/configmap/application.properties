####URL####
url-country-service=${URL_COUNTRY_SERVICE}
url-boundary-service=${URL_BOUNDARY_SERVICE}
url-dpi-nr-command-service=${URL_DPI_NR_COMMAND_SERVICE}
url-dpi-com-view-service=${URL_DPI_COM_VIEW_SERVICE}
####URL####
################################################### DB CONFIGURATION
#ORACLE CONFIG
#spring.datasource.url=${DB_URL}
#spring.datasource.username=${DB_USERNAME}
#spring.datasource.password=${DB_PASSWORD}
spring.datasource.jndi-name=jdbc/oracleDboardDpiComCommand
spring.datasource.driver-class=oracle.jdbc.driver.OracleDriver
#Hikari connection Pool https://github.com/brettwooldridge/HikariCP#configuration-knobs-baby
spring.datasource.hikari.connection-timeout=20000
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.maximum-pool-size=12
spring.datasource.hikari.idle-timeout=300000
spring.datasource.hikari.max-lifetime=1200000
#HIBERNATE CONFIG
spring.jpa.hibernate.ddl-auto=none
spring.jpa.properties.hibernate.show_sql=false
spring.jpa.properties.hibernate.use_sql_comments=true
spring.jpa.properties.hibernate.format_sql=true
logging.level.org.hibernate.type.descriptor.sql.BasicBinder=error
#######APPLICATION MONITORING################
#Actuator Configuration (default is /actuator)
info.app.name=Dboard Dpi Com Command Service Application
info.app.version=1.0.0
#######APPLICATION MONITORING################
###### METRICS ##################
management.endpoints.web.exposure.include=health,info,metrics,prometheus
management.endpoint.metrics.enabled=true
management.endpoint.prometheus.enabled=true
management.metrics.export.prometheus.enabled=true
###### METRICS ##################
spring.sleuth.messaging.kafka.enabled=false
#######KAFKA PRODUCER SETTING################
# ID to pass to the server when making requests. Used for server-side logging.
spring.kafka.client-id=Dpi-com-command
# Nummber of retry to contact Kafka
spring.kafka.producer.retries=5
# Comma-delimited list of host:port pairs to use for establishing the initial connections to the Kafka cluster. Overrides the global property, for producers.
spring.kafka.producer.bootstrap-servers=${SERVERS_KAFKA}
#spring.kafka.producer.bootstrap-servers=188.165.204.214:9092
# Serializer for key and value
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer= it.sogei.kafka.event.GenericKafkaEventSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
producer.producer-name=DPI-NATIONAL-COMMAND
spring.kafka.producer.properties.max.request.size=5242880
spring.kafka.consumer.properties.max.poll.interval.ms=2000000
spring.kafka.producer.acks=all
spring.kafka.properties.enable.idempotence=true
spring.kafka.properties.transactional.id=${MY_ADDRESS}
#######KAFKA CONSUMER SETTING################
# Unique string that identifies the consumer group to which this consumer belongs.
spring.kafka.consumer.group-id=Dpi-common-command
# Comma-delimited list of host:port pairs to use for establishing the initial connections to the Kafka cluster. Overrides the global property, for consumers.
spring.kafka.consumer.bootstrap-servers=${SERVERS_KAFKA}
# What to do when there is no initial offset in Kafka or if the current offset no longer exists on the server.
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.listener.ack-mode=manual
spring.kafka.consumer.isolation-level=read_committed
#######KAFKA CONSUMER SETTING################
########TOPICS################
topic.dpiCommandSideErr=${TOPIC_DPI_COMMAND_SIDE_ERR}
topic.dpiCommandSideCommand=${TOPIC_DPI_COMMAND_SIDE_COMMAND}
topic.dpiCommandSideEvent=${TOPIC_DPI_COMMAND_SIDE_EVENT}
topic.boundaryServiceDpiEvent=${TOPIC_BOUNDARY_SERVICE_DPI_EVENT}
topic.dpiDueDateServiceEvent=${DPI_DUE_DATE_SERVICE_EVENT}
topic.topicDpiNrCommandSideEvent=${TOPIC_DPI_NR_COMMAND_SIDE_EVENT}
topic.dpiCountryCommandSideEvent=${TOPIC_DPI_COUNTRY_COMMAND_SIDE_EVENT}
########TOPICS################
#######EVENT #####################
event.processHistory=${EVENT_PROCESS_HISTORY}
event.updateNotes=${EVENT_UPDATE_NOTES}
event.updateStatus=${EVENT_UPDATE_STATUS}
event.deleteCommunication=${EVENT_DELETE_COMMUNICATION}
event.expiredFiscalYear=${EXPIRED_FISCAL_YEAR}
event.updateFiscalYear=${UPDATE_FISCAL_YEAR}
event.buildMessage=${EVENT_BUILD_MESSAGE}
event.updateEffectiveDest=${EVENT_UPDATE_EFFECTIVE_DEST}
event.finalizeCommunication=${EVENT_FINALIZE_COMMUNICATION}
event.addEffectiveDest=${EVENT_ADD_EFFECTIVE_DEST}
event.removeEffectiveDest=${EVENT_REMOVE_EFFECTIVE_DEST}
event.restoredCountry=${EVENT_RESTORED_COUNTRY}
event.accededCountry=${EVENT_ACCEDED_COUNTRY}
event.blockedCountry=${EVENT_BLOCKED_COUNTRY}
event.lateCommunication=${EVENT_LATE_COMMUNICATION}
########EVENT ################
########KAFKA SECURITY################
spring.kafka.properties.security.protocol=SASL_SSL
spring.kafka.properties.sasl.mechanism=SCRAM-SHA-256
spring.kafka.properties.ssl.truststore.location=/config/resources/security/truststore.jks
spring.kafka.properties.ssl.truststore.password=${PSW_TRUSTSTORE}
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="${KAFKA_USER-ENT-SA-0396_FU_003}" password="${KAFKA_PASSWORD-ENT-SA-0396_FU_003}";
########KAFKA SECURITY################
